{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2famEwB-XwX","executionInfo":{"status":"ok","timestamp":1745065301949,"user_tz":-300,"elapsed":1924,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}},"outputId":"d5b4dc5a-83b8-40d7-dd27-cf44fb200677"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DQWGMT3buE0V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745065306391,"user_tz":-300,"elapsed":4444,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}},"outputId":"380a9030-f9a9-4ce1-afb9-b02407670bf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n"]}],"source":["# Install required Python libraries for data preprocessing, model training, and optional web deployment\n","\n","!pip install nltk scikit-learn pandas numpy flask-ngrok\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SvuB0kRX1deE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745065310884,"user_tz":-300,"elapsed":4495,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}},"outputId":"a00b94fd-cbda-4d03-d46b-c5fd597261db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"]}],"source":["# prompt: instal sklearn for feature extration text\n","\n","!pip install -U scikit-learn\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"TUV53ae0txlh","executionInfo":{"status":"ok","timestamp":1745065310919,"user_tz":-300,"elapsed":32,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Import necessary libraries for data handling, visualization, and ML\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","import re\n","import string"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"aWQIrDzTtxh4","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1745065310984,"user_tz":-300,"elapsed":63,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}},"outputId":"040a23d2-2231-4cb2-ac40-c1a3f774aa37"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/True.csv/True.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a622506d96b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the datasets (True and Fake news)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/True.csv/True.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Fake.csv/Fake.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/True.csv/True.csv'"]}],"source":["# Load the datasets (True and Fake news)\n","\n","true = pd.read_csv('/content/drive/MyDrive/True.csv/True.csv')\n","fake = pd.read_csv('/content/drive/MyDrive/Fake.csv/Fake.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVS0wItstxde","executionInfo":{"status":"aborted","timestamp":1745065310991,"user_tz":-300,"elapsed":1,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Preview the first few rows of the real news dataset\n","\n","true.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9Sx9I1itxWC","executionInfo":{"status":"aborted","timestamp":1745065310996,"user_tz":-300,"elapsed":1,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Preview the first few rows of the fake news dataset\n","\n","fake.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IB6N5Q1jgNK5","executionInfo":{"status":"aborted","timestamp":1745065311001,"user_tz":-300,"elapsed":1,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Add a 'label' column: 1 for True, 0 for Fake\n","\n","fake['label']= 0\n","true['label']= 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74uw2d87uKZd","executionInfo":{"status":"aborted","timestamp":1745065311004,"user_tz":-300,"elapsed":11253,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# checking the rows and colums in data sets\n","fake.shape, true.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjwONO7iuKQo","executionInfo":{"status":"aborted","timestamp":1745065311057,"user_tz":-300,"elapsed":9,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Create manual testing dataset and remove these samples from the main datasets.\n","\n","fake_manual_testing = fake.tail(10) # Extract the last 10 rows of the 'fake' DataFrame for manual testing\n","for i in range(23480,23470,-1):    # Iterate in reverse order to remove the last 10 rows from 'fake'\n","    fake.drop([i], axis=0, inplace=True)  # Remove rows by index to avoid issues with shifting indices\n","\n","true_manual_testing = true.tail(10) # Extract the last 10 rows of the 'true' DataFrame for manual testing\n","for i in range(21416,21406,-1):  # Iterate in reverse order to remove the last 10 rows from 'true'\n","    true.drop([i], axis=0, inplace=True)   # Remove rows by index to avoid issues with shifting indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkLXxavmuKNg","executionInfo":{"status":"aborted","timestamp":1745065311062,"user_tz":-300,"elapsed":12,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Add a 'label' column to the manual testing datasets: 0 for Fake, 1 for True\n","\n","\n","fake_manual_testing['label']= 0   # Assign label 0 to all rows in 'fake_manual_testing'\n","true_manual_testing['label']= 1   # Assign label 1 to all rows in 'true_manual_testing'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghN0MZciuKH0","executionInfo":{"status":"aborted","timestamp":1745065311065,"user_tz":-300,"elapsed":14,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Display the first 5 rows of the 'fake_manual_testing' DataFrame.\n","# This allows for a quick preview of the data that was set aside\n","# for manual testing of the fake news detection model.\n","\n","fake_manual_testing.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUx_2yORuKEd","executionInfo":{"status":"aborted","timestamp":1745065311105,"user_tz":-300,"elapsed":52,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Display the first 5 rows of the 'true_manual_testing' DataFrame.\n","# This allows for a quick preview of the data that was set aside\n","# for manual testing of the fake news detection model.\n","\n","true_manual_testing.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cdr5Xig3vL3s","executionInfo":{"status":"aborted","timestamp":1745065311109,"user_tz":-300,"elapsed":41,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Concatenate the fake and true manual testing DataFrames into a single DataFrame\n","manual_testing = pd.concat([fake_manual_testing, true_manual_testing], axis=0)\n","\n","# Save the combined manual testing data to a CSV file named 'manual_testing.csv'\n","manual_testing.to_csv('manual_testing.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3JJajHMvge1","executionInfo":{"status":"aborted","timestamp":1745065311111,"user_tz":-300,"elapsed":42,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Assuming 'fake' and 'true' are DataFrames containing fake and real news data respectively\n","\n","# Concatenate the 'fake' and 'true' DataFrames vertically\n","# to create a single DataFrame called 'df_marge'\n","# axis=0 specifies that the DataFrames should be stacked on top of each other\n","df_marge = pd.concat([fake, true], axis=0)"]},{"cell_type":"code","source":["# Display the first 5 rows of the 'df_marge' DataFrame\n","# to preview the combined dataset\n","df_marge.head()"],"metadata":{"id":"u8uLSPWHHjfX","executionInfo":{"status":"aborted","timestamp":1745065311114,"user_tz":-300,"elapsed":44,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teLjf5W5vny7","executionInfo":{"status":"aborted","timestamp":1745065311116,"user_tz":-300,"elapsed":45,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Display the last 5 rows of the 'df_marge' DataFrame\n","# to preview the combined dataset\n","df_marge.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XWWNEbDevu26","executionInfo":{"status":"aborted","timestamp":1745065311119,"user_tz":-300,"elapsed":1,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Display the column names of the 'df_marge' dataframe.\n","df_marge.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDjzeBJQv6mr","executionInfo":{"status":"aborted","timestamp":1745065311123,"user_tz":-300,"elapsed":11347,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Drop the 'title' , 'date' and 'subject' columns from both datasets\n","df = df_marge.drop(['title', 'subject', 'date'], axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2L-3F2w5wFN3","executionInfo":{"status":"aborted","timestamp":1745065311127,"user_tz":-300,"elapsed":11349,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Check for missing values (nulls) in the DataFrame 'df'.\n","# This is crucial for data cleaning as missing values can\n","# negatively impact model training and accuracy.\n","# The .isnull() method identifies missing values,\n","# and .sum() calculates the total for each column.\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiIGUEhHwT7w","executionInfo":{"status":"aborted","timestamp":1745065311130,"user_tz":-300,"elapsed":11349,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Shuffle the DataFrame 'df' in-place to randomize the order of rows.\n","# This is important for avoiding potential biases during model training\n","# that could arise from the original order of the data.\n","# 'frac=1' indicates sampling 100% of the data, effectively shuffling all rows.\n","df = df.sample(frac = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sc5dwOAswhfe","executionInfo":{"status":"aborted","timestamp":1745065311133,"user_tz":-300,"elapsed":11349,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Display the first 5 rows of the DataFrame for quick preview\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APvWk0nYwkhO","executionInfo":{"status":"aborted","timestamp":1745065311135,"user_tz":-300,"elapsed":11349,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Reset the index\n","df.reset_index(inplace = True)\n","# Remove the old index\n","df.drop(['index'], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-X0lAEgxF5u","executionInfo":{"status":"aborted","timestamp":1745065311137,"user_tz":-300,"elapsed":11348,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# for the quick preview\n","df.head()"]},{"cell_type":"markdown","source":["here\n","\n"],"metadata":{"id":"DYsmui9yMUT6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6uKm8m8xHrI","executionInfo":{"status":"aborted","timestamp":1745065311140,"user_tz":-300,"elapsed":11348,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["\n","    # Cleans and preprocesses text for NLP tasks by:\n","    # - Converting to lowercase\n","    # - Removing brackets, URLs, HTML tags, and punctuation\n","    # - Replacing non-alphanumeric characters with spaces\n","    # - Removing words containing numbers\n","\n","def wordopt(text):\n","      text = text.lower()\n","      text = re.sub('\\[.*?\\]', '', text)\n","      text = re.sub(\"\\\\W\", \" \", text)\n","      text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n","      text = re.sub('<.*?>+', '', text)\n","      text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n","      text = re.sub('\\n', '', text)\n","      text = re.sub('\\w*\\d\\w*', '', text)\n","  return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82LzD-ppyW2R","executionInfo":{"status":"aborted","timestamp":1745065311145,"user_tz":-300,"elapsed":11349,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# storing clean dataframe df\n","\n","df[\"text\"] = df[\"text\"].apply(wordopt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gmPVk_gyaJx","executionInfo":{"status":"aborted","timestamp":1745065311149,"user_tz":-300,"elapsed":11350,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Define feature variable (X) and target variable (y) for the model.\n","# X will contain the text content of the news articles.\n","# y will contain the labels (0 for fake, 1 for real).\n","\n","x = df[\"text\"]\n","y = df['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XU9aNqMNy9wL","executionInfo":{"status":"aborted","timestamp":1745065311151,"user_tz":-300,"elapsed":11349,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Split the data into training and testing sets\n","# x: Input features (news text content)\n","# y: Target variable (news labels - 0 for fake, 1 for real)\n","# test_size: Proportion of data to include in the test set (25% in this case)\n","# x_train, y_train: Training data (features and labels)\n","# x_test, y_test: Testing data (features and labels)\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oF7ojjtEkHZ8","executionInfo":{"status":"aborted","timestamp":1745065311154,"user_tz":-300,"elapsed":11350,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Import the TfidfVectorizer class from scikit-learn for text feature extraction\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Create a TfidfVectorizer object with default parameters\n","vectorization = TfidfVectorizer()\n","\n","# Fit the vectorizer to the training data (x_train) and transform it into a numerical representation\n","# This learns the vocabulary and IDF weights from the training data and creates the document-term matrix\n","xv_train = vectorization.fit_transform(x_train)\n","\n","# Transform the testing data (x_test) using the fitted vectorizer\n","# This ensures that the testing data is represented using the same vocabulary and IDF weights as the training data\n","xv_test = vectorization.transform(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w88hDQ6Enrz5","executionInfo":{"status":"aborted","timestamp":1745065311208,"user_tz":-300,"elapsed":6,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Import the Logistic Regression model from scikit-learn\n","from sklearn.linear_model import LogisticRegression\n","\n","# Create an instance of the Logistic Regression model\n","# We're using the default parameters for now, but these can be customized\n","LR = LogisticRegression()\n","\n","# Train the model using the training data\n","# xv_train: The features (text content transformed into numerical representation) of the training data\n","# y_train: The corresponding labels (0 for fake, 1 for real) for the training data\n","# The 'fit' method adjusts the model's internal parameters to learn from the training data\n","LR.fit(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueaG9NBfn23s","executionInfo":{"status":"aborted","timestamp":1745065311211,"user_tz":-300,"elapsed":8,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Make predictions on the test set using the trained Logistic Regression model (LR)\n","# xv_test: The features (text content transformed into numerical representation) of the test data\n","# pred_lr: A variable to store the predicted labels (0 for fake, 1 for real) for the test data\n","pred_lr = LR.predict(xv_test)\n","\n","# Evaluate the performance of the Logistic Regression model (LR) on the training data\n","# xv_train: The features (text content transformed into numerical representation) of the training data\n","# y_train: The corresponding labels (0 for fake, 1 for real) for the training data\n","# This line calculates and prints the accuracy score of the model on the training data\n","LR.score(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wW-p76Cwn6o7","executionInfo":{"status":"aborted","timestamp":1745065311213,"user_tz":-300,"elapsed":8,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Evaluate the performance of the Logistic Regression model on the test set\n","# by printing a classification report.\n","# This report provides key metrics such as precision, recall, F1-score,\n","# and support for each class (Fake and Real news).\n","# It helps assess the model's ability to correctly classify news articles.\n","\n","print(classification_report(y_test, pred_lr))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rn1QGLHloX2O","executionInfo":{"status":"aborted","timestamp":1745065311214,"user_tz":-300,"elapsed":8,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Import, create, and train a Bernoulli Naive Bayes model\n","from sklearn.naive_bayes import BernoulliNB\n","\n","NB = BernoulliNB() # Create a Bernoulli Naive Bayes object\n","NB.fit(xv_train, y_train) # Train the model using training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lv_vsC5wolEw","executionInfo":{"status":"aborted","timestamp":1745065311216,"user_tz":-300,"elapsed":9,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Use the trained Naive Bayes model (NB) to predict labels for the test set (xv_test)\n","# and store the predictions in the 'pred_nb' variable.\n","pred_nb = NB.predict(xv_test)\n","\n","# Calculate and print (implicitly) the accuracy score of the Naive Bayes model on the training data (xv_train, y_train).\n","# This provides an evaluation of how well the model learned from the training data.\n","NB.score(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoTRuNfCoq0b","executionInfo":{"status":"aborted","timestamp":1745065311218,"user_tz":-300,"elapsed":11400,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Evaluate the performance of the Naive Bayes model on the test set\n","# by printing a classification report.\n","# This report provides key metrics such as precision, recall, F1-score,\n","# and support for each class (Fake and Real news).\n","# It helps assess the model's ability to correctly classify news articles.\n","print(classification_report(y_test, pred_nb))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ON-0TGo1os1Z","executionInfo":{"status":"aborted","timestamp":1745065311223,"user_tz":-300,"elapsed":2,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Import the DecisionTreeClassifier class from scikit-learn's tree module\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Create a DecisionTreeClassifier object with default settings\n","# This will be our decision tree model\n","DT = DecisionTreeClassifier()\n","\n","# Train the decision tree model using the training data\n","# xv_train: The features (preprocessed text data)\n","# y_train: The corresponding labels (0 for fake, 1 for real)\n","DT.fit(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-TxPqU_pCVA","executionInfo":{"status":"aborted","timestamp":1745065311226,"user_tz":-300,"elapsed":11403,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Make predictions on the test set using the trained Decision Tree model\n","# xv_test: The features (preprocessed text data) of the test set\n","# pred_dt: A variable to store the predicted labels (0 for fake, 1 for real)\n","pred_dt = DT.predict(xv_test)\n","\n","# Evaluate the performance of the Decision Tree model on the training data\n","# xv_train: The features (preprocessed text data) of the training set\n","# y_train: The true labels for the training set\n","# This line calculates and prints (implicitly) the accuracy score\n","DT.score(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQRyUchPpHQ-","executionInfo":{"status":"aborted","timestamp":1745065311229,"user_tz":-300,"elapsed":11404,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Evaluate the performance of the Decision Tree model on the test set\n","# by printing a classification report.\n","# This report provides key metrics such as precision, recall, F1-score,\n","# and support for each class (Fake and Real news).\n","# It helps assess the model's ability to correctly classify news articles.\n","\n","print(classification_report(y_test, pred_dt))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TO2qgzXzpKef","executionInfo":{"status":"aborted","timestamp":1745065311230,"user_tz":-300,"elapsed":11401,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Import the RandomForestClassifier class from scikit-learn's ensemble module\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Create a RandomForestClassifier object with default settings\n","# This will be our Random Forest model\n","RFC = RandomForestClassifier()\n","\n","# Train the Random Forest model using the training data\n","# xv_train: The features (preprocessed text data)\n","# y_train: The corresponding labels (0 for fake, 1 for real)\n","RFC.fit(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBl9E8g7pMgs","executionInfo":{"status":"aborted","timestamp":1745065311232,"user_tz":-300,"elapsed":11398,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Make predictions on the test set using the trained Random Forest model\n","pred_rfc = RFC.predict(xv_test)\n","\n","# Evaluate the model's performance on the training data using the score method\n","# This gives you an idea of how well the model learned from the training data\n","# but doesn't necessarily reflect its performance on unseen data (test set)\n","RFC.score(xv_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ito1Hzm6pVeB","executionInfo":{"status":"aborted","timestamp":1745065311237,"user_tz":-300,"elapsed":1,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Evaluate the performance of the Random Forest model on the test set\n","# by printing a classification report.\n","# This report provides key metrics such as precision, recall, F1-score,\n","# and support for each class (Fake and Real news).\n","# It helps assess the model's ability to correctly classify news articles.\n","\n","print(classification_report(y_test, pred_rfc))   # Print the classification report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGFbXEESpliq","executionInfo":{"status":"aborted","timestamp":1745065311244,"user_tz":-300,"elapsed":11402,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"outputs":[],"source":["# Define a function to convert numerical labels (0 or 1) to text labels (\"Fake News\" or \"Real News\")\n","def output_lable(n):\n","    if n == 0:\n","        return \"Fake News\" # If n is 0, it's fake news\n","    elif n == 1:\n","        return \"Real News\"  # If n is 1, it's real news\n","\n","# Define a function for manual testing of news articles\n","def manual_testing(news):\n","\n","     # Create a dictionary to store the news article text\n","    testing_news = {\"text\":[news]}\n","     # Convert the dictionary to a Pandas DataFrame\n","    new_def_test = pd.DataFrame(testing_news)\n","     # Apply the wordopt function to clean and preprocess the text\n","    new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt)\n","     # Extract the preprocessed text\n","    new_x_test = new_def_test[\"text\"]\n","    # Vectorize the text using the previously fitted vectorizer\n","    new_xv_test = vectorization.transform(new_x_test)\n","    # Make predictions using the four trained models\n","    pred_LR = LR.predict(new_xv_test)  # Logistic Regression prediction\n","    pred_NB = NB.predict(new_xv_test)  # Naive Bayes prediction\n","    pred_DT = DT.predict(new_xv_test)  # Decision Tree prediction\n","    pred_RFC = RFC.predict(new_xv_test) # Random Forest prediction\n","    # Print the predictions of all four models with readable labels\n","    return print(\"\\n\\nLR Prediction: {} \\nNB Prediction: {} \\nDT Prediction: {} \\nRFC Prediction: {}\".format(output_lable(pred_LR[0]),  # Convert LR prediction to text label\n","                                                                                                              output_lable(pred_NB[0]), # Convert NB prediction to text label\n","                                                                                                              output_lable(pred_DT[0]), # Convert DT prediction to text label\n","                                                                                                              output_lable(n=pred_RFC[0])))  # Convert RFC prediction to text label\n"]},{"cell_type":"code","source":["# Get news input from the user\n","news = str(input())\n","\n","# Call the manual_testing function to classify the news\n","manual_testing(news)"],"metadata":{"id":"UMsSKwK96Moh","executionInfo":{"status":"aborted","timestamp":1745065311247,"user_tz":-300,"elapsed":11399,"user":{"displayName":"Nauman Toheed","userId":"13568201963853117367"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1iD17Mdr9VcV2ECgl06qy8qHFlG48kCpO","timestamp":1744044208928}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}